{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk transformers torch annoy seaborn matplotlib scikit-learn PyPDF2 plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import PyPDF2\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn import DataParallel\n",
    "import torch\n",
    "from paper_processing_for_embeddings import preprocess_and_read \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "# If multiple GPUs are available, use DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = DataParallel(model)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs_in_parallel(folder_path, n, num_workers=8):\n",
    "    all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    processed_files = all_files[:n]\n",
    "\n",
    "    with Pool(num_workers) as p:\n",
    "        results = list(tqdm(p.imap(preprocess_and_read, processed_files), total=len(processed_files)))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_words_batch(words):\n",
    "    inputs = tokenizer(words, padding=True, return_tensors='pt', truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move inputs to the appropriate device\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.hidden_states[-1][:, 0, :].detach().cpu().numpy()\n",
    "\n",
    "def create_embeddings_from_preprocessed_data(preprocessed_data, batch_size):\n",
    "    all_embeddings = {}\n",
    "\n",
    "    for words, file_path in preprocessed_data:\n",
    "        unique_words = list(set(words))\n",
    "        cached_embeddings = defaultdict(lambda: None)\n",
    "\n",
    "        for i in range(0, len(unique_words), batch_size):\n",
    "            batch_words = unique_words[i:i + batch_size]\n",
    "            batch_embeddings = embed_words_batch(batch_words)\n",
    "\n",
    "            for word, embedding in zip(batch_words, batch_embeddings):\n",
    "                all_embeddings[word] = {\n",
    "                    'embedding': embedding,\n",
    "                    'file': file_path\n",
    "                }\n",
    "\n",
    "    return all_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snapshot_download(repo_id='PromptSystematicReview/Prompt_Systematic_Review_Dataset', \n",
    "                  repo_type='dataset', \n",
    "                  local_dir='./PapersDirectory', \n",
    "                  allow_patterns=['papers/*'], \n",
    "                  local_dir_use_symlinks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pdfs_in_directory(directory_path):\n",
    "    return len([f for f in os.listdir(directory_path) if f.endswith('.pdf') and os.path.isfile(os.path.join(directory_path, f))])\n",
    "\n",
    "# Set the path to the directory containing the papers\n",
    "papers_path = './PapersDirectory/papers'\n",
    "batch_size = 25\n",
    "\n",
    "# Count the number of PDFs in the directory to process all available papers\n",
    "num_papers_to_process = count_pdfs_in_directory(papers_path)\n",
    "\n",
    "# Continue with processing\n",
    "preprocessed_data = process_pdfs_in_parallel(papers_path, num_papers_to_process)\n",
    "embeddings_dict = create_embeddings_from_preprocessed_data(preprocessed_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming embeddings_dict is your dictionary\n",
    "with open('word_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, Apr  7 2023, 21:05:46) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
