{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# instantiate openAI client with .env\n",
    "client = OpenAI()\n",
    "\n",
    "s_data_path = \"../data/SCS-training-data\"\n",
    "\n",
    "# list all files in s_data_path\n",
    "files = os.listdir(s_data_path)\n",
    "\n",
    "s_data = {}\n",
    "\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    with open(file_path) as f:\n",
    "        result = [json.loads(jline) for jline in f.read().splitlines()]\n",
    "        return result\n",
    "\n",
    "\n",
    "# go through all .jsonl files in files\n",
    "# create valid file path (s_data_path + file)\n",
    "# read in the file as a jsonl file using json library\n",
    "# store object in s_data dictionary with key as file name\n",
    "for file in files:\n",
    "    if file.endswith(\".jsonl\"):\n",
    "        file_path = s_data_path + \"/\" + file\n",
    "        s_data[file.removesuffix(\"_train.jsonl\")] = read_jsonl(file_path)\n",
    "print(s_data.keys())\n",
    "\n",
    "the_word = \"\".join(chr(i) for i in [115, 117, 105, 99, 105, 100, 101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forbidden_imports import *\n",
    "\n",
    "scs_rubric = {\n",
    "    \"Entrapment\": \"Feeling like there is no exit, feeling hopeless, feeling like there is no way out, feeling afraid that things will never be normal again, feeling helpless to change, feeling trapped, feeling doomed, feeling or thinking that things will never change, feeling like there is no escape, feeling like there are no good solutions to problems.\",\n",
    "    \"Affective Disturbance\": \"Emotional Pain: Having a sense of inner pain that is too much to bear, feeling relentless agonizing emotional pain, feeling a sense of inner pain that has to be stopped, feeling like the emotional pain is unbearable. Self-disgust and Self-loathing: Feeling intense deep and/or negative feelings directed toward the self, describing self with expletives. Rapid Spikes of Negative Emotion: Feeling any intense, deep, and/or quickly changing negative feelings or mood swings directed toward the self or someone else. Extreme Anxiety: Feeling nervousness or shakiness, feeling blood rushing through veins, feeling unusual physical sensations, dissociation and somatic symptoms. Acute Anhedonia: Feeling dissatisfied or bored with everything, feeling a lost interest in other people, not finding pleasure in hobbies and pastimes, not enjoying being with family or close friends.\",\n",
    "    \"Loss of Cognitive Control\": \"Rumination: Focusing on one topic repeatedly, having racing or excessive thoughts about one or few topics, feeling like ideas are turning over and over in the mind and aren’t able to go away. Cognitive Rigidity: Rarely changing mind, stuck on one idea; inflexible, feeling like mind cannot be easily changed over things that are bothersome, feeling like mind can never change once a decision/conclusion has been made. Ruminative Flooding: Feeling like head could explode from too many thoughts, having a decreased ability to think, concentrate or make decisions, feeling pressure in head from thinking too much, feeling like a headache is developing from too many thoughts. Failed Thought Suppression: Wanting troubling thoughts to go away but unable to make them stop, feeling powerless to stop upsetting thoughts, feeling like it is hard to stop worrying.\",\n",
    "    \"Hyperarousal\": \"Agitation: Feeling tensed or keyed up, feeling so restless that there is an inability to sit still, feeling a desire to crawl out of one’s skin, feeling so stirred up inside like wanting to scream, feeling a lot of emotional turmoil in gut. Hypervigilance: Feeling that staying alert and watchful is needed to prevent something bad from happening, constantly watching for signs of trouble, feeling that most people cannot be trusted. Irritability: Having uncontrollable temper outbursts, getting into frequent arguments, feeling easily annoyed or irritated, having a short fuse. Insomnia: Having trouble falling asleep because of uncontrollable thoughts, difficulties falling asleep, staying asleep or waking up too early, waking up from sleep tired and not refreshed, not sleeping enough hours.\",\n",
    "    \"Social Withdrawal\": \"Interacting less with people who care, feeling unable to open up to family members or friends, feeling isolated from others, evading communications with people who care, pushing away caring people.NOTE: This is distinguished from perceived burdensomeness/thwarted belongingness through behavioral actions of social withdrawal, as opposed to simply having thoughts related to disconnection/burdensomeness. It should be ACUTE rather than more subacute/chronic.\",\n",
    "}\n",
    "\n",
    "scs_rubric_discrete = {\n",
    "    \"Entrapment\": [\n",
    "        \"feeling like there is no exit\",\n",
    "        \"feeling hopeless\",\n",
    "        \"feeling like there is no way out\",\n",
    "        \"feeling afraid that things will never be normal again\",\n",
    "        \"feeling helpless to change\",\n",
    "        \"feeling trapped\",\n",
    "        \"feeling doomed\",\n",
    "        \"feeling or thinking that things will never change\",\n",
    "        \"feeling like there is no escape\",\n",
    "        \"feeling like there are no good solutions to problems\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "rtfmap = {  # rubric name to file name map\n",
    "    \"Entrapment\": \"entrapment\",\n",
    "    \"Affective Disturbance\": \"disturbance\",\n",
    "    \"Loss of Cognitive Control\": \"control\",\n",
    "    \"Hyperarousal\": \"hyperarousal\",\n",
    "    \"Social Withdrawal\": \"withdrawal\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(results):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"accept\":\n",
    "            tp += 1\n",
    "        elif result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"reject\":\n",
    "            fn += 1\n",
    "        elif result[\"label\"] == \"reject\" and result[\"predicted_label\"] == \"accept\":\n",
    "            fp += 1\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "    except:\n",
    "        print(\"F1 cant be computed becuase of division by zero\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def accuracy_score(results):\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == result[\"predicted_label\"]:\n",
    "            correct += 1\n",
    "    return correct / len(results)\n",
    "\n",
    "\n",
    "def precision_score(results):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"accept\":\n",
    "            tp += 1\n",
    "        elif result[\"label\"] == \"reject\" and result[\"predicted_label\"] == \"accept\":\n",
    "            fp += 1\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "\n",
    "def recall_score(results):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"accept\":\n",
    "            tp += 1\n",
    "        elif result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"reject\":\n",
    "            fn += 1\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "\n",
    "def count_false_positives(results):\n",
    "    fp = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"reject\" and result[\"predicted_label\"] == \"accept\":\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "\n",
    "def count_false_negatives(results):\n",
    "    fn = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"reject\":\n",
    "            fn += 1\n",
    "    return fn\n",
    "\n",
    "\n",
    "def count_true_positives(results):\n",
    "    tp = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"accept\" and result[\"predicted_label\"] == \"accept\":\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "\n",
    "def count_true_negatives(results):\n",
    "    tn = 0\n",
    "    for result in results:\n",
    "        if result[\"label\"] == \"reject\" and result[\"predicted_label\"] == \"reject\":\n",
    "            tn += 1\n",
    "    return tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_just_GPT(string, rubric_category, reasoning_length=7):\n",
    "    \"\"\"\n",
    "    :param string: the text to be labeled\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message_just_gpt.format(\n",
    "                    the_word=the_word,\n",
    "                    rubric_category=rubric_category,\n",
    "                    rubric=scs_rubric[rubric_category],\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt_just_gpt.format(\n",
    "                    string=string,\n",
    "                    rubric_category=rubric_category,\n",
    "                    reasoning_length=reasoning_length,\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    content = json.loads(response.choices[0].message.content)\n",
    "    label = content.get(\"label\", \"Not provided\")\n",
    "    reasoning = content.get(\"reasoning\", \"No reasoning provided\")\n",
    "    return {\n",
    "        \"text\": string,\n",
    "        \"predicted_label\": label,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "\n",
    "\n",
    "for i in rtfmap:\n",
    "    results = []\n",
    "    for text in tqdm.tqdm(s_data[rtfmap[i]]):\n",
    "        responseDict = get_answer_just_GPT(text[\"text\"], i)\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": text[\"text\"],\n",
    "                \"label\": text[\"answer\"],\n",
    "                \"predicted_label\": responseDict[\"predicted_label\"],\n",
    "                \"reasoning\": responseDict[\"reasoning\"],\n",
    "            }\n",
    "        )\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    json.dump(results, open(f\"{i}_results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_answer_just_GPT(\"I feel stuck\", \"Entrapment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 scores for JUST GPT\")\n",
    "for i in rtfmap:\n",
    "    results = json.load(open(f\"../data/s_data/just_gpt/{i}_results.json\"))\n",
    "\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    print(f\"Accuracy for {i}: {accuracy_score(results)}\")\n",
    "    print(f\"Precision for {i}: {precision_score(results)}\")\n",
    "    print(f\"Recall for {i}: {recall_score(results)}\")\n",
    "    print(f\"False Positives for {i}: {count_false_positives(results)}\")\n",
    "    print(f\"False Negatives for {i}: {count_false_negatives(results)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_just_GPT_strict(string, rubric_category, reasoning_length=7):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message_just_gpt_strict.format(\n",
    "                    the_word=the_word,\n",
    "                    rubric_category=rubric_category,\n",
    "                    rubric=scs_rubric[rubric_category],\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt_just_gpt_strict.format(\n",
    "                    string=string,\n",
    "                    rubric_category=rubric_category,\n",
    "                    reasoning_length=reasoning_length,\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    content = json.loads(response.choices[0].message.content)\n",
    "    label = content.get(\"label\", \"Not provided\")\n",
    "    reasoning = content.get(\"reasoning\", \"No reasoning provided\")\n",
    "    return {\n",
    "        \"text\": string,\n",
    "        \"predicted_label\": label,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "\n",
    "\n",
    "for i in rtfmap:\n",
    "    results = []\n",
    "\n",
    "    for text in tqdm.tqdm(s_data[rtfmap[i]]):\n",
    "        responseDict = get_answer_just_GPT_strict(text[\"text\"], i)\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": text[\"text\"],\n",
    "                \"label\": text[\"answer\"],\n",
    "                \"predicted_label\": responseDict[\"predicted_label\"],\n",
    "                \"reasoning\": responseDict[\"reasoning\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    json.dump(results, open(f\"../data/s_data/just_gpt_strict/{i}_results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 scores for JUST GPT STRICT\")\n",
    "for i in rtfmap:\n",
    "    results = json.load(open(f\"../data/s_data/just_gpt_strict/{i}_results.json\"))\n",
    "\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    print(f\"Accuracy for {i}: {accuracy_score(results)}\")\n",
    "    print(f\"Precision for {i}t: {precision_score(results)}\")\n",
    "    print(f\"Recall for {i}: {recall_score(results)}\")\n",
    "    print(f\"False Positives for {i}: {count_false_positives(results)}\")\n",
    "    print(f\"False Negatives for {i}: {count_false_negatives(results)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_CoT(string, rubric_category, reasoning_length=7):\n",
    "    system_message = \"\"\"You are a useful lab assistant and the world's leading {the_word} researcher. Your job is to read a string of text from social media and help categorize it as {rubric_category} or not {rubric_category}. {rubric_category} is formally defined as: {scs_rubric[rubric_category]}. Now that you know what {rubric_category} is, when given a question asking whether or not a social media post is {rubric_category} you will respond with an ouput that starts with 'Answer: ', followed by point by point explanation that goes through the definiton of {rubric_category} and assesses whether the given post meets that point of the criteria. Finally, the end of your answer should start with the string '#FINAL ANSWER# ' followed by either 'accept' if the post is {rubric_category} or 'reject' if the post is not {rubric_category}. LISTEN CAREFULLY, this part is very important. Be VERY very literally in your interpretation of the rubric. It is safer to reject than to accept.\"\"\"\n",
    "\n",
    "    cot_prompt = f\"Question: is the following social media post [Social media post: {sample1_cot1}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer1_cot1}\\nQuestion: is the following social media post [Social media post: {sample2_cot1}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer2_cot1}\\n\"\n",
    "    user_prompt = f\"Question: is the following social media post [Social media post: {string}] an instance of {rubric_category}? Let's think this step by step \\nAnswer:\"\n",
    "    user_prompt = cot_prompt + user_prompt\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    label = content.split(\"#FINAL ANSWER# \")[-1].strip()\n",
    "    reasoning = content.split(\"#FINAL ANSWER# \")[0].removeprefix(\"Answer: \").strip()\n",
    "    # label = content.get(\"label\", \"Not provided\")\n",
    "    # reasoning = content.get(\"reasoning\", \"No reasoning provided\")\n",
    "    return {\n",
    "        \"text\": string,\n",
    "        \"predicted_label\": label,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "\n",
    "\n",
    "for i in rtfmap:\n",
    "    if i.lower() != \"hyperarousal\":\n",
    "        continue\n",
    "    results = []\n",
    "\n",
    "    for text in tqdm.tqdm(s_data[rtfmap[i]]):\n",
    "        responseDict = get_answer_CoT(text[\"text\"], i)\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": text[\"text\"],\n",
    "                \"label\": text[\"answer\"],\n",
    "                \"predicted_label\": responseDict[\"predicted_label\"],\n",
    "                \"reasoning\": responseDict[\"reasoning\"],\n",
    "            }\n",
    "        )\n",
    "    # print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    json.dump(results, open(f\"../data/s_data/cot/{i}_results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 scores for 1st COT\")\n",
    "for i in rtfmap:\n",
    "    results = json.load(open(f\"../data/s_data/cot/{i}_results.json\"))\n",
    "    print(f\"Accuracy for {i}: {accuracy_score(results)}\")\n",
    "    print(f\"True Positives for {i}: {count_true_positives(results)}\")\n",
    "    print(f\"True Negatives for {i}: {count_true_negatives(results)}\")\n",
    "    print(f\"False Positives for {i}: {count_false_positives(results)}\")\n",
    "    print(f\"False Negatives for {i}: {count_false_negatives(results)}\")\n",
    "    print(f\"Precision for {i}: {precision_score(results)}\")\n",
    "    print(f\"Recall for {i}: {recall_score(results)}\")\n",
    "\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_CoT2(string, rubric_category):\n",
    "    system_message = f\"\"\"\n",
    "    You are a useful lab assistant and the world's leading {the_word} researcher. Your job is to read a string of text from social media and help categorize it as {rubric_category} or not {rubric_category}. {rubric_category} is formally defined as: {scs_rubric[rubric_category]}. Now that you know what {rubric_category} is, when given a question asking whether or not a social media post is {rubric_category} you will respond with an ouput that starts with 'Answer: ', followed by a lengthy and thorough point by point explanation that goes through the definiton of {rubric_category} and assesses whether the given post meets each point of the criteria. Finally, the end of your answer should start with the string '#FINAL ANSWER# ' followed by either 'accept' if the post is {rubric_category} or 'reject' if the post is not {rubric_category}. LISTEN CAREFULLY, this part is very important. Be VERY very literal in your interpretation of the rubric and the post. DO NOT read into the post beyond the words you are given (for example, using concepts such as 'tone' and 'mood' to decide the final answer). It is safer to reject than to accept.\"\"\"\n",
    "\n",
    "    cot_prompt = f\"Question: is the following social media post [Social media post: {sample1_cot2}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer1_cot2}\\nQuestion: is the following social media post [Social media post: {sample2_cot2}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer2_cot2}\\n\"\n",
    "    user_prompt = f\"Question: is the following social media post [Social media post: {string}] an instance of {rubric_category}? Let's think this step by step \\nAnswer:\"\n",
    "    user_prompt = cot_prompt + user_prompt\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    label = content.split(\"#FINAL ANSWER# \")[-1].strip()\n",
    "    reasoning = content.split(\"#FINAL ANSWER# \")[0].removeprefix(\"Answer: \").strip()\n",
    "    # label = content.get(\"label\", \"Not provided\")\n",
    "    # reasoning = content.get(\"reasoning\", \"No reasoning provided\")\n",
    "    return {\n",
    "        \"text\": string,\n",
    "        \"predicted_label\": label,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "\n",
    "\n",
    "for i in rtfmap:\n",
    "    if i.lower() != \"hyperarousal\":\n",
    "        continue\n",
    "    results = []\n",
    "\n",
    "    for text in tqdm.tqdm(s_data[rtfmap[i]]):\n",
    "        responseDict = get_answer_CoT2(text[\"text\"], i)\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": text[\"text\"],\n",
    "                \"label\": text[\"answer\"],\n",
    "                \"predicted_label\": responseDict[\"predicted_label\"],\n",
    "                \"reasoning\": responseDict[\"reasoning\"],\n",
    "            }\n",
    "        )\n",
    "    # print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    json.dump(results, open(f\"../data/s_data/cot/{i}2_results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 scores for 2nd COT\")\n",
    "for i in rtfmap:\n",
    "    results = json.load(open(f\"../data/s_data/cot/{i}2_results.json\"))\n",
    "    print(f\"Accuracy for {i}: {accuracy_score(results)}\")\n",
    "    print(f\"True Positives for {i}: {count_true_positives(results)}\")\n",
    "    print(f\"True Negatives for {i}: {count_true_negatives(results)}\")\n",
    "    print(f\"False Positives for {i}: {count_false_positives(results)}\")\n",
    "    print(f\"False Negatives for {i}: {count_false_negatives(results)}\")\n",
    "    print(f\"Precision for {i}: {precision_score(results)}\")\n",
    "    print(f\"Recall for {i}: {recall_score(results)}\")\n",
    "\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_CoT3(string, rubric_category):\n",
    "    system_message = f\"\"\"\n",
    "    You are a useful lab assistant and the world's leading {the_word} researcher. Your job is to read a string of text from social media and help categorize it as {rubric_category} or not {rubric_category}. {rubric_category} is formally defined as: {scs_rubric[rubric_category]}. Now that you know what {rubric_category} is, when given a question asking whether or not a social media post is {rubric_category} you will respond with an ouput that starts with 'Answer: ', followed by a lengthy and thorough point by point explanation that goes through the definiton of {rubric_category} and assesses whether the given post meets each point of the criteria. Finally, the end of your answer should start with the string '#FINAL ANSWER# ' followed by either 'accept' if the post is {rubric_category} or 'reject' if the post is not {rubric_category}. LISTEN CAREFULLY, this part is very important. Be VERY very literal in your interpretation of the rubric and the post. DO NOT read into the post beyond the words you are given (for example, using concepts such as 'tone' and 'mood' to decide the final answer). It is safer to reject than to accept. Your final decision must be based on the rubric. IMPORTANT: If atleast one point is thouroughly met, then the post is {rubric_category}. If no points are met or are met very weakly, then the post is not {rubric_category}.\"\"\"\n",
    "\n",
    "    cot_prompt = f\"Question: is the following social media post [Social media post: {sample1_cot3}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer1_cot3}\\nQuestion: is the following social media post [Social media post: {sample2_cot3}] an instance of {rubric_category}? Let's think this step by step \\nAnswer: {answer2_cot3}\\n\"\n",
    "    user_prompt = f\"Question: is the following social media post [Social media post: {string}] an instance of {rubric_category}? Let's think this step by step \\nAnswer:\"\n",
    "    user_prompt = cot_prompt + user_prompt\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        # response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    label = content.split(\"#FINAL ANSWER# \")[-1].strip()\n",
    "    reasoning = content.split(\"#FINAL ANSWER# \")[0].removeprefix(\"Answer: \").strip()\n",
    "    # label = content.get(\"label\", \"Not provided\")\n",
    "    # reasoning = content.get(\"reasoning\", \"No reasoning provided\")\n",
    "    return {\n",
    "        \"text\": string,\n",
    "        \"predicted_label\": label,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "\n",
    "\n",
    "for i in rtfmap:\n",
    "    results = []\n",
    "\n",
    "    for text in tqdm.tqdm(s_data[rtfmap[i]]):\n",
    "        responseDict = get_answer_CoT3(text[\"text\"], i)\n",
    "        results.append(\n",
    "            {\n",
    "                \"text\": text[\"text\"],\n",
    "                \"label\": text[\"answer\"],\n",
    "                \"predicted_label\": responseDict[\"predicted_label\"],\n",
    "                \"reasoning\": responseDict[\"reasoning\"],\n",
    "            }\n",
    "        )\n",
    "    # print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    json.dump(results, open(f\"../data/s_data/cot/{i}3_results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 scores for 3rd COT\")\n",
    "for i in rtfmap:\n",
    "    results = json.load(open(f\"../data/s_data/cot/{i}3_results.json\"))\n",
    "\n",
    "    print(f\"Accuracy for {i}: {accuracy_score(results)}\")\n",
    "    print(f\"True Positives for {i}: {count_true_positives(results)}\")\n",
    "    print(f\"True Negatives for {i}: {count_true_negatives(results)}\")\n",
    "    print(f\"False Positives for {i}: {count_false_positives(results)}\")\n",
    "    print(f\"False Negatives for {i}: {count_false_negatives(results)}\")\n",
    "    print(f\"Precision for {i}: {precision_score(results)}\")\n",
    "    print(f\"Recall for {i}: {recall_score(results)}\")\n",
    "\n",
    "    print(f\"F1 for {i}: {f1_score(results)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
