{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk transformers torch annoy seaborn matplotlib scikit-learn PyPDF2 plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aayushgupta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aayushgupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import PyPDF2\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn import DataParallel\n",
    "import torch\n",
    "from paper_processing_for_embeddings import preprocess_and_read \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "# If multiple GPUs are available, use DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_words_batch(words):\n",
    "    inputs = tokenizer(words, padding=True, return_tensors='pt', truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move inputs to the appropriate device\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.hidden_states[-1][:, 0, :].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_annoy_index(embeddings_dict):\n",
    "    f = list(embeddings_dict.values())[0]['embedding'].shape[0]\n",
    "    t = AnnoyIndex(f, 'angular')\n",
    "    for i, (word, data) in enumerate(embeddings_dict.items()):\n",
    "        t.add_item(i, data['embedding'])\n",
    "    t.build(10)\n",
    "    return t\n",
    "\n",
    "def query_similar_words(query, index, embeddings_dict, top_n=5):\n",
    "    query_embedding = embed_words_batch([query])[0]  # Embed the query word\n",
    "    nearest_ids = index.get_nns_by_vector(query_embedding, top_n)\n",
    "\n",
    "    similar_words_with_titles = []\n",
    "    for i in nearest_ids:\n",
    "        word = list(embeddings_dict.keys())[i]\n",
    "        title = embeddings_dict[word]['file'].split('/')[-1]  # Extract the file name\n",
    "        similar_words_with_titles.append((word, title))\n",
    "\n",
    "    return similar_words_with_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_embeddings.pkl', 'rb') as f:\n",
    "    embeddings_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Annoy index\n",
    "annoy_index = build_annoy_index(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Enhances normalization of text by lowercasing, replacing hyphens and underscores, \n",
    "    and removing non-alphanumeric characters.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\-\\_]', ' ', text)  # Replace hyphens and underscores with spaces\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def user_approval(technique):\n",
    "    \"\"\"\n",
    "    Asks for user approval for a new technique.\n",
    "    \"\"\"\n",
    "    response = input(f\"Approve technique '{technique}'? (y/n): \").strip().lower()\n",
    "    return response == 'y'\n",
    "\n",
    "def find_nearest_neighbors(techniques, seen_techniques, embeddings_dict, annoy_index, depth=0, max_depth=10):\n",
    "    \"\"\"\n",
    "    Recursively finds nearest neighbors for a list of techniques up to a certain depth.\n",
    "    Each new technique requires user approval.\n",
    "    \"\"\"\n",
    "    if depth >= max_depth:\n",
    "        print(f\"Maximum depth reached: {max_depth}\")\n",
    "        return techniques\n",
    "\n",
    "    new_techniques = set()\n",
    "    for technique in techniques:\n",
    "        similar_words = query_similar_words(technique, annoy_index, embeddings_dict, top_n=10)\n",
    "        for word, _ in similar_words:\n",
    "            normalized_word = normalize_text(word)\n",
    "            if normalized_word not in seen_techniques:\n",
    "                seen_techniques.add(normalized_word)\n",
    "                if user_approval(normalized_word):\n",
    "                    new_techniques.add(normalized_word)\n",
    "\n",
    "    # Check for new techniques\n",
    "    if not new_techniques:\n",
    "        print(\"No new approved techniques found\")\n",
    "        return techniques\n",
    "\n",
    "    # Add new techniques and recurse with updated sets\n",
    "    updated_techniques = techniques.union(new_techniques)\n",
    "    print(f\"Depth {depth}: Found {len(new_techniques)} new approved techniques\")\n",
    "    return find_nearest_neighbors(updated_techniques, seen_techniques, embeddings_dict, annoy_index, depth+1, max_depth)\n",
    "\n",
    "# Example usage\n",
    "initial_techniques = set([\n",
    "    \"Chain of Thought [CoT]\",\n",
    "    \"Zero-shot-CoT\",\n",
    "    \"Few-Shot-Chain-of-Thought\",\n",
    "    \"Plan-and-Solve Prompting\",\n",
    "    \"OPRO\",\n",
    "    \"Tree-of-Thought\",\n",
    "    \"Skeleton-of-Thought\",\n",
    "    \"Active-Prompt\",\n",
    "    \"Contrastive Chain of Thought\",\n",
    "    \"Complexity-based prompting\",\n",
    "    \"Faithful Chain-of-Thought\",\n",
    "    \"Memory-of-Thought\",\n",
    "    \"Recursion of Thought\",\n",
    "    \"Auto-Cot\",\n",
    "    \"Automate-CoT\",\n",
    "    \"Program-of-Thoughts\",\n",
    "    \"Tab-CoT\",\n",
    "    \"Think Aloud\",\n",
    "    \"Golden CoT\",\n",
    "    \"ICAP\",\n",
    "    \"Graph-of-Thoughts\",\n",
    "    \"Self-Evaluation\",\n",
    "    \"Self-refine\",\n",
    "    \"Verify-and-edit\",\n",
    "    \"CRITIC\",\n",
    "    \"AuRoRA\",\n",
    "    \"Self-Ask\",\n",
    "    \"Iterative Prompts\",\n",
    "    \"Prompt Mining\",\n",
    "    \"Prompt Paraphrasing\",\n",
    "    \"Self-improvement framework\",\n",
    "    \"Least-to-most prompting\",\n",
    "    \"Maieutic Prompting\",\n",
    "    \"Directional-stimulus prompting\",\n",
    "    \"Automatic Prompt Generation\",\n",
    "    \"Self-Instruct\",\n",
    "    \"Cumulative Reasoning\",\n",
    "    \"In-Context Learning\",\n",
    "    \"Few-shot learning (FSL)\",\n",
    "    \"Few-shot prompting (FSP)\",\n",
    "    \"Input-Label Pairing format\",\n",
    "    \"Label Space\",\n",
    "    \"Input Distribution\",\n",
    "    \"Input-Label mapping\",\n",
    "    \"Demonstration Ensembling (DENSE)\",\n",
    "    \"Self-Consistency\",\n",
    "    \"DiVeRSe\",\n",
    "    \"Zero-Shot Prompt\",\n",
    "    \"Role Prompting\",\n",
    "    \"Style Prompting\",\n",
    "    \"Emotion Prompting\",\n",
    "    \"Re-reading\",\n",
    "    \"Negative Prompting\"\n",
    "])\n",
    "\n",
    "seen_techniques = set(initial_techniques)  # Initialize seen techniques with the initial set\n",
    "max_depth = 2  # You can adjust this to control the recursion depth\n",
    "\n",
    "# Modified recursive function call\n",
    "all_techniques = find_nearest_neighbors(initial_techniques, seen_techniques, embeddings_dict, annoy_index, max_depth=max_depth)\n",
    "\n",
    "print(\"All approved techniques found:\")\n",
    "for technique in all_techniques:\n",
    "    print(technique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, Apr  7 2023, 21:05:46) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
